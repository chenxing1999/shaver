import random
from typing import Dict, List, Literal, Optional

import numpy as np
import torch
from sklearn.metrics import roc_auc_score
from torch.nn import functional as F

from .base import CTRModel


def get_mask(
    x,
    feat_to_keeps,
    level: Literal["feat", "fields", "weight"],
):
    """
    Args:
        x: torch.LongTensor - Shape: Batch x #Fields
        feat_to_keeps: torch.LongTensor - Shape: K

    Returns:
        return mask: torch.BoolTensor - shape: same with x
            mask[i, j] = 1 if we keep that value
    """
    if level == "feat":
        return _get_mask_feat(x, feat_to_keeps)
    elif level == "fields":
        mask = torch.zeros_like(x, dtype=torch.bool)
        mask[:, feat_to_keeps] = 1
        return mask
    else:
        raise NotImplementedError()


def get_mask_batch(
    x,
    feat_to_keeps,
    level: Literal["feat", "fields", "weight"],
):
    """
    Args:
        x: torch.LongTensor - Shape: Batch x #Fields
        feat_to_keeps: torch.BoolTensor - Shape: Batch x #Feats

    Returns:
        return mask: torch.BoolTensor - shape: same with x
            mask[i, j] = 1 if we keep that value
    """
    if level == "feat":
        return _get_mask_feat(x, feat_to_keeps)
    else:
        raise NotImplementedError()


def _get_mask_feat(
    x: torch.LongTensor, feat_to_keeps: torch.LongTensor
) -> torch.Tensor:
    """
    Return S with the same shape with x
    so that if x[i, j] in feat_to_keeps then S[i, j] = 1 else S[i, j] = 0

    Args:
        x: torch.LongTensor - Shape: Batch x #Fields
        feat_to_keeps: torch.LongTensor - Shape: K

    Returns:
        S: Shape: Batch x # Feats

    Note: Generated by ChatGPT. Confirmed having correct logic.
    """
    # Expand the dimensions of x and feat_to_keeps for broadcasting
    x_expanded = x.unsqueeze(-1)  # Shape: Batch x #Feats x 1

    is_batched_feat = len(feat_to_keeps.shape)
    if is_batched_feat == 1:
        feat_to_keeps_expanded = feat_to_keeps.unsqueeze(0).unsqueeze(
            0
        )  # Shape: 1 x 1 x K
    elif is_batched_feat == 2:
        assert feat_to_keeps.shape[0] == x.shape[0]

        # Shape: Batch x 1 x K
        feat_to_keeps_expanded = feat_to_keeps.unsqueeze(1)

    # Check which elements of x are in feat_to_keeps
    # This creates a boolean mask of the same shape as x
    mask = torch.any(x_expanded == feat_to_keeps_expanded, dim=-1)

    # mask = ~mask
    return mask


def get_offsets(field_dims: List[int]) -> torch.Tensor:
    field_dims_tensor = torch.tensor(field_dims)
    field_dims_tensor = torch.cat(
        [torch.tensor([0], dtype=torch.long), field_dims_tensor]
    )
    offsets = torch.cumsum(field_dims_tensor[:-1], 0).unsqueeze(0)

    return offsets


def _get_mask_feat_batch(
    x: torch.LongTensor,
    feat_to_keeps: torch.LongTensor,
) -> torch.Tensor:
    """
    Return S with the same shape with x
    so that if x[i, j] in feat_to_keeps then S[i, j] = 1 else S[i, j] = 0

    Args:
        x: torch.LongTensor - Shape: Batch x #Fields
        feat_to_keeps: list[torch.LongTensor] - Shape: Batch, K

    Returns:
        S: Shape: Batch x # Feats

    Note: Generated by ChatGPT. Confirmed having correct logic.
    """
    # Expand the dimensions of x and feat_to_keeps for broadcasting
    x_expanded = x.unsqueeze(-1)  # Shape: Batch x #Feats x 1
    feat_to_keeps_expanded = feat_to_keeps.unsqueeze(0).unsqueeze(0)  # Shape: 1 x 1 x K

    # Check which elements of x are in feat_to_keeps
    # This creates a boolean mask of the same shape as x
    mask = torch.any(x_expanded == feat_to_keeps_expanded, dim=-1)

    # mask = ~mask
    return mask


class ImportanceTracker:
    """For tracking feature importance using a dynamic average."""

    def __init__(self):
        self.mean = 0
        self.sum_squares = 0
        self.N = 0

    def update(self, scores, num_samples=None):
        """
        Update mean and sum of squares using Welford's algorithm.

        Args:
          scores: array of consisting of n samples with shape (n, dim).
          num_samples: array of size (dim,) representing the number of samples
            for each dimension. For sparse updates, with void samples
            represented by zeros.
        """
        if num_samples is None:
            # Welford's algorithm.
            self.N += len(scores)
            diff = scores - self.mean
            self.mean += torch.sum(diff, 0) / self.N
            diff2 = scores - self.mean
            self.sum_squares += torch.sum(diff * diff2, 0)
        else:
            # Welford's algorithm with correction for void samples.
            assert num_samples.shape == scores.shape[1:]
            self.N = self.N + num_samples
            num_void = len(scores) - num_samples
            orig_mean = np.copy(self.mean)
            diff = scores - self.mean
            self.mean += (torch.sum(diff, 0) + self.mean * num_void) / torch.max(
                self.N, 1
            )
            diff2 = scores - self.mean
            self.sum_squares += (
                torch.sum(diff * diff2, 0) - orig_mean * self.mean * num_void
            )

    @property
    def values(self):
        return self.mean

    @property
    def var(self):
        # print('sum_squares', self.sum_squares)
        return self.sum_squares / (np.maximum(self.N, 1) ** 2)

    @property
    def std(self):
        return self.var**0.5


@torch.no_grad()
def validate_epoch(
    val_loader,
    model: CTRModel,
    device="cuda",
    ori_model: Optional[CTRModel] = None,
) -> Dict[str, float]:
    """Validate single epoch performance

    Args:
        val_dataloader
        model
        device
    Returns:
        "auc"
        "log_loss"
    """

    model.eval()
    model = model.to(device)

    criterion = torch.nn.BCEWithLogitsLoss(reduction="sum")
    criterion = criterion.to(device)

    log_loss = 0.0
    kldiv_loss = 0.0
    all_y_true = []
    all_y_pred = []

    for idx, batch in enumerate(val_loader):
        inputs, labels = batch
        all_y_true.extend(labels.tolist())

        inputs = inputs.to(device)
        labels = labels.to(device)

        outputs = model(inputs)

        log_loss += criterion(outputs, labels.float()).item()

        outputs = torch.sigmoid(outputs)
        if ori_model is not None:
            ori_outputs = torch.sigmoid(ori_model(inputs))
            kldiv_loss += F.kl_div(outputs.log(), ori_outputs, reduction="sum").item()

        all_y_pred.extend(outputs.cpu().tolist())

    auc = roc_auc_score(all_y_true, all_y_pred)
    log_loss = log_loss / len(all_y_pred)
    kldiv_loss = kldiv_loss / len(all_y_pred)

    results = {
        "auc": auc,
        "log_loss": log_loss,
    }
    if ori_model is not None:
        results["kldiv"] = kldiv_loss
    return results


def get_freq_avg(
    weight: torch.Tensor,
    freq: torch.Tensor,
    field_dims: torch.Tensor,
) -> torch.Tensor:
    """

    Args:
        weight (shape Num Features x HiddenSize)
        freq (shape Num Features)
        field_dims (shape Num Fields)

    Returns:
        shape Num Fields x Hidden Size

    """
    base_value = []
    start, end = 0, 0

    freq = freq.unsqueeze(-1)
    for offsets in field_dims:
        end = end + offsets

        s = freq[start:end] * weight[start:end]
        m = s.sum(0) / freq[start:end].sum()
        base_value.append(m)
        start = end

    base_value = torch.stack(base_value, 0)
    return base_value


def get_feat_to_field(field_dims) -> torch.Tensor:
    result = []
    for idx, offsets in enumerate(field_dims):
        result.extend([idx] * offsets)

    return torch.tensor(result)


def set_seed(seed):
    np.random.seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
    torch.manual_seed(seed)
    random.seed(seed)


def post_training_quantization(tensor: torch.Tensor, n_bits=16):
    assert n_bits in [8, 16, 4]

    q_min = (-1) * (1 << (n_bits - 1))
    q_max = (1 << (n_bits - 1)) - 1
    r_min = tensor.min().cpu()
    scale = (tensor.max().item() - r_min) / (q_max - q_min)

    dtype = torch.int8
    if n_bits == 16:
        dtype = torch.int16

    bias = (q_min - r_min / scale).to(dtype)
    tensor = torch.round(tensor / scale + bias)
    tensor = tensor.to(dtype)

    tensor = (tensor - bias) * scale
    return tensor
