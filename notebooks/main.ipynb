{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f54c8b9a-0d39-4790-b334-ce61065bf4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.sage_row import RowDefaultImputer, sage_shapley_field_ver\n",
    "from src.utils import get_freq_avg, set_seed, validate_epoch\n",
    "from src.models.codebook_emb import CodebookEmb\n",
    "\n",
    "import random\n",
    "\n",
    "set_seed(2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335bfbd8-a7af-4345-8104-b1ebe3a93a9e",
   "metadata": {},
   "source": [
    "# Create MockModel and MockDataset for sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbbbc7e-ae65-4971-92db-6aff15605de7",
   "metadata": {},
   "source": [
    "First, we need to create `Model` class. We provide an example below.\n",
    "\n",
    "To use real model, you can use function `src.models.get_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de447605-be09-446f-8ba3-769c0f6c3789",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.base import CTRModel \n",
    "\n",
    "# CTRModel is an interface class. In Python, you can just simply inheritance from `nn.Module`.\n",
    "class MockModel(CTRModel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        field_dims: list[int],\n",
    "        hidden_size: int = 4,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self._field_dims: torch.Tensor = torch.tensor(field_dims)\n",
    "\n",
    "        # Make sure your instance have `self.embedding` is instance of nn.Embedding\n",
    "        self.embedding = nn.Embedding(sum(field_dims), hidden_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: torch.LongTensor - Shape: Batch x #Fields\n",
    "                x is a vector already include offsets\n",
    "                \n",
    "        Returns:\n",
    "            y: Logit, Shape: Batch x 1\n",
    "        \"\"\"\n",
    "        emb = self.get_emb(x)\n",
    "        return self.head(emb, x)\n",
    "\n",
    "    def get_emb(self, x=None):\n",
    "        if x is None:\n",
    "            return self.embedding.weight\n",
    "\n",
    "        return self.embedding(x)\n",
    "\n",
    "    def head(self, emb, x):\n",
    "\n",
    "        # A simple forward method to represent model.head\n",
    "        return emb.sum((1, 2))\n",
    "    \n",
    "    def get_emb_size(self):\n",
    "        return self.embedding.weight.shape\n",
    "\n",
    "    @property\n",
    "    def field_dims(self):\n",
    "        return self._field_dims\n",
    "\n",
    "    # def remove_feat(self, feat_to_remove):\n",
    "        \n",
    "    #     self._backup = self.embedding.weight.data.clone()\n",
    "    #     self.embedding.weight.data[feat_to_remove] = 0\n",
    "\n",
    "    # def recover(self):\n",
    "    #     self.embedding.weight.data = self._backup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ae7257-bef8-4b81-a9ef-812233f75745",
   "metadata": {},
   "source": [
    "Next, we create `Dataset` class. We provide an example below.\n",
    "\n",
    "To use real dataset, you can use function `src.datasets.get_dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59806a4e-b5d3-45d0-a192-420ea6f34076",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.base import CTRDataset\n",
    "\n",
    "class MockDataset(CTRDataset):\n",
    "    \"\"\"Dataset to generate random data for CTR task\n",
    "    Used for mocking input and output flow\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        field_dims: list[int],\n",
    "        num_items: int = 10,\n",
    "        *,\n",
    "        include_offsets: bool = True,\n",
    "        seed: int = 2023,\n",
    "        distribution=\"uniform\",\n",
    "        label_distribution=\"equal\",\n",
    "    ):\n",
    "        assert distribution in [\"uniform\", \"long-tail\"]\n",
    "\n",
    "        self.field_dims = field_dims\n",
    "        self.num_items = sum(field_dims)\n",
    "        self._include_offsets = include_offsets\n",
    "\n",
    "        rng = random.Random(seed)\n",
    "        seed = seed\n",
    "\n",
    "        data = []\n",
    "\n",
    "        for _ in range(num_items):\n",
    "            result = []\n",
    "            offsets = 0\n",
    "\n",
    "            for field in self.field_dims:\n",
    "                if distribution == \"uniform\":\n",
    "                    item = rng.randrange(0, field)\n",
    "                elif distribution == \"long-tail\":\n",
    "                    item = rng.choices(\n",
    "                        range(field),\n",
    "                        weights=range(field, 0, -1),\n",
    "                        k=1,\n",
    "                    )[0]\n",
    "\n",
    "                if self._include_offsets:\n",
    "                    item += offsets\n",
    "                    offsets += field\n",
    "\n",
    "                result.append(item)\n",
    "\n",
    "            if label_distribution == \"equal\":\n",
    "                label = sum(result) % 2\n",
    "            else:\n",
    "                label = (sum(result) % 4) == 0\n",
    "\n",
    "            data.append(\n",
    "                (torch.tensor(result), torch.tensor(label, dtype=torch.float32))\n",
    "            )\n",
    "\n",
    "        self.data = data\n",
    "        self._num_items = num_items\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._num_items\n",
    "\n",
    "    def pop_info(self):\n",
    "        return\n",
    "\n",
    "    def describe(self):\n",
    "        desc = (\n",
    "            \"MockDataset(\"\n",
    "            f\"field_dims={self.field_dims}\"\n",
    "            f\"include_offsets={self._include_offsets}\"\n",
    "            f\"num_item={self._num_items}\"\n",
    "            \")\"\n",
    "        )\n",
    "\n",
    "        print(desc)\n",
    "\n",
    "    def get_frequency(self):\n",
    "        freq = torch.zeros(sum(self.field_dims), dtype=torch.long)\n",
    "        for x, y in self.data:\n",
    "            freq[x] += 1\n",
    "        return freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "588134b4-1178-40d4-8601-0577b0371fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "field_dims = [3,3,4]\n",
    "hidden_size = 4\n",
    "model = MockModel(field_dims, hidden_size)\n",
    "dataset = MockDataset(field_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2de620-4568-43e9-938b-e12e58e51166",
   "metadata": {},
   "source": [
    "# Shaver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f396ae1-ef30-418c-a940-2a61d7c0d93e",
   "metadata": {},
   "source": [
    "**Step 1: Calculate Codebook**\n",
    "\n",
    "First, get frequency to compute Codebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce2f5648-be35-4bc8-beca-f039e0c87290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 3, 5, 5, 4, 1, 2, 4, 2, 2], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "freq = torch.zeros(sum(field_dims), dtype=torch.int)\n",
    "\n",
    "for x, _ in dataset:\n",
    "    freq[x] += 1\n",
    "print(freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a1fe76-9be6-4e97-a61e-61e140f973af",
   "metadata": {},
   "source": [
    "Get Codebook based on Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f079b258-fac4-4c93-bb99-17e1b5a9d9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4])\n",
      "tensor([[ 0.3590,  1.1874, -0.9712,  0.3223],\n",
      "        [-0.3600, -1.8097,  0.2276, -0.0137],\n",
      "        [ 0.2508, -0.5020,  0.2927,  0.6773]])\n"
     ]
    }
   ],
   "source": [
    "from src.utils import get_freq_avg\n",
    "\n",
    "codebook = get_freq_avg(\n",
    "    model.embedding.weight.data,\n",
    "    freq,\n",
    "    torch.tensor(field_dims),\n",
    ")\n",
    "print(codebook.shape) # Num Fields x Hidden Size = 3 x 4\n",
    "print(codebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d806cde9-b844-4702-8d47-5fbb5ca41ad9",
   "metadata": {},
   "source": [
    "**Step 2: Calculate Shapley Value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68ea4506-88b7-482b-a1c4-1e24f0f28ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings device\n",
    "device = \"cuda\"\n",
    "codebook = codebook.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b64946a-da23-4201-84a2-f2f3826c4641",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# To use Shaver-Zero, set base_value=0.\n",
    "\n",
    "imputer = RowDefaultImputer(\n",
    "    model,\n",
    "    use_sigmoid=True,  # Return sigmoid output,\n",
    "    base_value=codebook,  # Codebook value\n",
    ")\n",
    "\n",
    "loader = DataLoader(dataset)\n",
    "n_iters = 10000 # will only run maximum n_iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c6a8a72-78bf-49c6-bb28-6b38f67fd766",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "std=0.01 - ratio=0.01: 100%|#####################################################################################################################################################################| 10000/10000 [00:31<00:00, 321.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max diff 2.075857639312744\n",
      "mean diff -0.02797735799153646\n",
      "std diff -0.0007585209826121769\n",
      "total 120000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "value, std = sage_shapley_field_ver(\n",
    "    model,\n",
    "    loader,\n",
    "    n_iters,\n",
    "    imputer,\n",
    "    device=\"cuda\",\n",
    "    threshold=1e-2, # converge threshold\n",
    "    min_epochs=1, # ensure loop through the whole dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1ca44d2-995a-4396-87b3-7a930e851e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.960464477539062e-07\n"
     ]
    }
   ],
   "source": [
    "# Check efficiency condition\n",
    "gap = value.sum().item()\n",
    "\n",
    "target = 0\n",
    "count = 0\n",
    "for x, y in loader:\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    empty_s = torch.zeros(x.shape[0], x.shape[1], hidden_size, device=device, dtype=bool)\n",
    "    full_s = torch.ones(x.shape[0], x.shape[1], hidden_size, device=device, dtype=bool)\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        y_pred_empty = imputer(x, empty_s)\n",
    "        y_pred_full = imputer(x, full_s)\n",
    "\n",
    "        target += F.binary_cross_entropy(y_pred_empty, y, reduction=\"sum\") - F.binary_cross_entropy(y_pred_full, y, reduction=\"sum\")\n",
    "    count += x.shape[0]\n",
    "\n",
    "target = (target / count).item()\n",
    "\n",
    "print(abs(target - gap))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0437052-bef5-4f91-8325-49133f431eca",
   "metadata": {},
   "source": [
    "**Step 3: Prune the model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e94eb95-7c34-4ec3-bf8b-ba23e1a73cc4",
   "metadata": {},
   "source": [
    "validate original performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be80d60c-030d-4fed-9833-bb9622cf499b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'auc': np.float64(0.36), 'log_loss': 1.0432055294513702}\n"
     ]
    }
   ],
   "source": [
    "print(validate_epoch(loader, model, device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc971af-f840-4956-8e0a-c0465dfa69dd",
   "metadata": {},
   "source": [
    "do pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7aff023-7b7d-4eec-af48-7da30df392af",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows, n_cols = model.embedding.weight.shape\n",
    "ratio = 0.8 # set the sparse rate to 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcdf5426-c9f1-486d-a8d8-1f84066757d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapley_value = value.flatten().abs()\n",
    "\n",
    "\n",
    "num_ele = int(n_rows * n_cols * ratio)\n",
    "\n",
    "idx = torch.argsort(shapley_value)\n",
    "idx = idx[:num_ele]\n",
    "idx1 = idx // n_cols\n",
    "idx2 = idx % n_cols\n",
    "\n",
    "\n",
    "# mask, 1 means removed\n",
    "mask = torch.zeros_like(model.embedding.weight, dtype=bool)\n",
    "mask[idx1, idx2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "000006e5-9dc0-43bd-9c16-e6bb6e5d0530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate New embedding with codebook and mask\n",
    "emb = CodebookEmb(\n",
    "    mask,\n",
    "    model.embedding.weight,\n",
    "    codebook,\n",
    ")\n",
    "model.embedding = emb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f7c8f6-d3aa-4572-aace-ae87c3f1ba75",
   "metadata": {},
   "source": [
    "Validate the model on given `loader`. As this is a simple random model, we should hope for some performance improvement after pruning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be5ccf6d-3dc3-4f90-8f1c-44e7765be0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'auc': np.float64(0.66), 'log_loss': 0.8755695939064025}\n"
     ]
    }
   ],
   "source": [
    "print(validate_epoch(loader, model, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324f42f1-51d3-4142-9a93-f455d16b5885",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
